{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd '/content/drive/MyDrive/CV/25-2컴비'"],"metadata":{"id":"FbocquOimUhm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765583699414,"user_tz":-540,"elapsed":38235,"user":{"displayName":"‎김민지(인공지능대학 인공지능학과)","userId":"04033818291171900415"}},"outputId":"633bce44-0b89-4d00-8c39-a92f7859c019"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/.shortcut-targets-by-id/1aE_a_G0fPBK8xZhdBCIjPHz19X4kFBp1/25-2컴비\n"]}]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from pathlib import Path"],"metadata":{"id":"big7nmYHmLCI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class LeafPreprocessor:\n","    \"\"\"Preprocessing plant leaf images\"\"\"\n","\n","    def __init__(self, target_size=(224, 224)):\n","        self.target_size = target_size\n","\n","    def load_image(self, image_path):\n","        \"\"\"Load image\"\"\"\n","        img = cv2.imread(str(image_path))\n","        if img is None:\n","            raise ValueError(f\"Cannot load image: {image_path}\")\n","        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","    def remove_noise(self, image, method='gaussian'):\n","        \"\"\"Remove noise\n","        Args:\n","            image: input image\n","            method: 'gaussian', 'median', 'bilateral' 중 선택\n","        \"\"\"\n","        if method == 'gaussian': # smoothing\n","            return cv2.GaussianBlur(image, (5, 5), 0)\n","        elif method == 'median': # salt-and-pepper noise에 효과적\n","            return cv2.medianBlur(image, 5)\n","        elif method == 'bilateral': # preserve edge, remove noise\n","            return cv2.bilateralFilter(image, 9, 75, 75)\n","        return image\n","\n","    # Version 1\n","    def remove_background_green_mask_v1(self, image):\n","        \"\"\"녹색 픽셀 기반 배경 제거\"\"\"\n","        # RGB to HSV\n","        hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n","\n","        # 녹색 범위 정의 (잎 색상)\n","        # 여러 녹색 톤을 포착하기 위해 2개의 범위 사용\n","        lower_green1 = np.array([25, 40, 40])\n","        upper_green1 = np.array([85, 255, 255])\n","\n","        # 황녹색/밝은 녹색\n","        lower_green2 = np.array([35, 30, 30])\n","        upper_green2 = np.array([90, 255, 255])\n","\n","        # 마스크 생성\n","        mask1 = cv2.inRange(hsv, lower_green1, upper_green1)\n","        mask2 = cv2.inRange(hsv, lower_green2, upper_green2)\n","        mask = cv2.bitwise_or(mask1, mask2)\n","\n","        # 모폴로지 연산으로 마스크 정제\n","        kernel = np.ones((5, 5), np.uint8)\n","        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n","        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n","\n","        # 마스크 적용\n","        result = cv2.bitwise_and(image, image, mask=mask)\n","\n","        # 배경을 흰색으로 (선택사항: 검은색은 0, 흰색은 255)\n","        background = np.full(image.shape, 255, dtype=np.uint8)\n","        background_mask = cv2.bitwise_not(mask)\n","        background = cv2.bitwise_and(background, background, mask=background_mask)\n","        result = cv2.add(result, background)\n","\n","        return result, mask\n","\n","    def remove_background_grabcut(self, image):\n","        \"\"\"Remove background with GrabCut algorithm\"\"\"\n","        mask = np.zeros(image.shape[:2], np.uint8) # 마스크 초기화\n","\n","        # GrabCut 임시 배열\n","        bgd_model = np.zeros((1, 65), np.float64)\n","        fgd_model = np.zeros((1, 65), np.float64)\n","\n","        # ROI 정의: 이미지 중앙 80%\n","        h, w = image.shape[:2]\n","        rect = (int(w*0.1), int(h*0.1), int(w*0.8), int(h*0.8))\n","\n","        cv2.grabCut(image, mask, rect, bgd_model, fgd_model, 5, cv2.GC_INIT_WITH_RECT) # GrabCut 실행\n","\n","        # 확실한 전경과 가능한 전경을 합침\n","        mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n","\n","        result = image * mask2[:, :, np.newaxis] # 마스크 적용\n","\n","        # 배경을 흰색으로\n","        background = np.full(image.shape, 255, dtype=np.uint8)\n","        background_mask = 1 - mask2\n","        background = background * background_mask[:, :, np.newaxis]\n","        result = result + background\n","\n","        return result, mask2\n","\n","    # Version 2\n","    def remove_background_green_mask_v2(self, image):\n","        \"\"\"개선된 색상 기반 배경 제거 (녹색 + 갈색/황색 병변 포함)\"\"\"\n","        # RGB to HSV\n","        hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n","\n","        # 1. 녹색 범위 (건강한 잎)\n","        lower_green = np.array([25, 40, 40]) # H: 25-85, S: 40-255, V: 40-255 -> 이 범위를 포함\n","        upper_green = np.array([85, 255, 255])\n","        mask_green = cv2.inRange(hsv, lower_green, upper_green)\n","\n","        # 2. 황색 범위 (시든 잎, 일부 질병)\n","        lower_yellow = np.array([15, 40, 40])\n","        upper_yellow = np.array([35, 255, 255])\n","        mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n","\n","        # 3. 갈색 범위 (병든 부위, 마른 잎)\n","        # 갈색은 낮은 채도의 주황/빨강\n","        lower_brown = np.array([0, 20, 20])\n","        upper_brown = np.array([20, 200, 200])\n","        mask_brown = cv2.inRange(hsv, lower_brown, upper_brown)\n","\n","        # 모든 마스크 결합\n","        mask = cv2.bitwise_or(mask_green, mask_yellow)\n","        mask = cv2.bitwise_or(mask, mask_brown)\n","\n","        # 모폴로지 연산으로 마스크 정제\n","        kernel = np.ones((5, 5), np.uint8)\n","        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n","        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n","\n","        # 마스크 적용\n","        result = cv2.bitwise_and(image, image, mask=mask)\n","\n","        # 배경을 흰색으로 (선택사항: 검은색은 0, 흰색은 255)\n","        background = np.full(image.shape, 255, dtype=np.uint8)\n","        background_mask = cv2.bitwise_not(mask)\n","        background = cv2.bitwise_and(background, background, mask=background_mask)\n","        result = cv2.add(result, background)\n","\n","        return result, mask\n","\n","    def remove_background_hybrid(self, image):\n","        \"\"\"하이브리드: 색상 기반 + GrabCut 결합\n","\n","        1단계: 색상으로 대략적인 전경 영역 찾기\n","        2단계: GrabCut으로 정교하게 다듬기\n","        \"\"\"\n","        # 1단계: 색상 기반 초기 마스크\n","        hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n","\n","        # 녹색 + 황색 + 갈색\n","        lower_green = np.array([25, 40, 40])\n","        upper_green = np.array([85, 255, 255])\n","        mask_green = cv2.inRange(hsv, lower_green, upper_green)\n","\n","        lower_yellow = np.array([15, 40, 40])\n","        upper_yellow = np.array([35, 255, 255])\n","        mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n","\n","        lower_brown = np.array([0, 20, 20])\n","        upper_brown = np.array([20, 200, 200])\n","        mask_brown = cv2.inRange(hsv, lower_brown, upper_brown)\n","\n","        initial_mask = cv2.bitwise_or(mask_green, mask_yellow)\n","        initial_mask = cv2.bitwise_or(initial_mask, mask_brown)\n","\n","        # 모폴로지로 정제\n","        kernel = np.ones((5, 5), np.uint8)\n","        initial_mask = cv2.morphologyEx(initial_mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n","        initial_mask = cv2.morphologyEx(initial_mask, cv2.MORPH_OPEN, kernel, iterations=1)\n","\n","        # 2단계: GrabCut으로 정교화\n","        # 초기 마스크를 GrabCut의 시작점으로 사용\n","        mask_grabcut = np.where(initial_mask > 0, cv2.GC_PR_FGD, cv2.GC_PR_BGD).astype('uint8')\n","\n","        bgd_model = np.zeros((1, 65), np.float64)\n","        fgd_model = np.zeros((1, 65), np.float64)\n","\n","        # GrabCut 실행 (반복 횟수 줄여서 속도 향상)\n","        try:\n","            cv2.grabCut(image, mask_grabcut, None, bgd_model, fgd_model, 3, cv2.GC_INIT_WITH_MASK)\n","            final_mask = np.where((mask_grabcut == 2) | (mask_grabcut == 0), 0, 1).astype('uint8')\n","        except:\n","            # GrabCut 실패 시 초기 마스크 사용\n","            final_mask = (initial_mask > 0).astype('uint8')\n","\n","        # 마스크 적용\n","        result = cv2.bitwise_and(image, image, mask=final_mask)\n","\n","        # 배경을 흰색으로\n","        background = np.full(image.shape, 255, dtype=np.uint8)\n","        background_mask = cv2.bitwise_not(final_mask * 255)\n","        background = cv2.bitwise_and(background, background, mask=background_mask)\n","        result = cv2.add(result, background)\n","\n","        return result, final_mask\n","        \"\"\"GrabCut 알고리즘으로 배경 제거\"\"\"\n","        # 마스크 초기화\n","        mask = np.zeros(image.shape[:2], np.uint8)\n","\n","        # GrabCut 임시 배열\n","        bgd_model = np.zeros((1, 65), np.float64)\n","        fgd_model = np.zeros((1, 65), np.float64)\n","\n","        # 관심 영역(ROI) 정의: 이미지 중앙 80%\n","        h, w = image.shape[:2]\n","        rect = (int(w*0.1), int(h*0.1), int(w*0.8), int(h*0.8))\n","\n","        # GrabCut 실행\n","        cv2.grabCut(image, mask, rect, bgd_model, fgd_model, 5, cv2.GC_INIT_WITH_RECT)\n","\n","        # 확실한 전경과 가능한 전경을 합침\n","        mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n","\n","        # 마스크 적용\n","        result = image * mask2[:, :, np.newaxis]\n","\n","        # 배경을 흰색으로\n","        background = np.full(image.shape, 255, dtype=np.uint8)\n","        background_mask = 1 - mask2\n","        background = background * background_mask[:, :, np.newaxis]\n","        result = result + background\n","\n","        return result, mask2\n","\n","    def apply_otsu_threshold(self, image):\n","        \"\"\"Otsu thresholding\"\"\"\n","        if len(image.shape) == 3:\n","            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) # grayscale transformation\n","        else:\n","            gray = image\n","\n","        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n","\n","        return binary\n","\n","    def watershed_segmentation(self, image):\n","        \"\"\"Watershed 알고리즘으로 객체 분리\"\"\"\n","        # grayscale, binary\n","        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n","        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n","\n","        # 노이즈 제거\n","        kernel = np.ones((3, 3), np.uint8)\n","        opening = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=2)\n","\n","        sure_bg = cv2.dilate(opening, kernel, iterations=3) # 확실한 배경 영역\n","\n","        # 확실한 전경 영역\n","        dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n","        _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n","        sure_fg = np.uint8(sure_fg)\n","\n","        unknown = cv2.subtract(sure_bg, sure_fg) # 불확실한 영역\n","\n","        _, markers = cv2.connectedComponents(sure_fg) # 마커 라벨링\n","        markers = markers + 1\n","        markers[unknown == 255] = 0\n","\n","        markers = cv2.watershed(image, markers) # Watershed 적용\n","\n","        result = image.copy() # mark boundary with red color\n","        result[markers == -1] = [255, 0, 0]\n","\n","        return result, markers\n","\n","    def preprocess_pipeline(self, image_path, method='simple'):\n","        \"\"\"\n","        Args:\n","            image_path: 이미지 경로\n","            method: 'simple', 'advanced', 'grabcut' 중 선택\n","\n","        Returns:\n","            processed_image, intermediate_results (시각화용)\n","        \"\"\"\n","        # 1. Load image\n","        original = self.load_image(image_path)\n","        results = {'original': original.copy()}\n","\n","        # 2. Resize\n","        resized = cv2.resize(original, (512, 512))  # 전처리용 큰 사이즈\n","        results['resized'] = resized.copy()\n","\n","        if method == 'simple': # Gaussian + Green mask v1\n","            # 3. Remove noise\n","            denoised = self.remove_noise(resized, method='gaussian')\n","            results['denoised'] = denoised.copy()\n","\n","            # 4. Remove background (Green mask)\n","            bg_removed, mask = self.remove_background_green_mask_v1(denoised)\n","            results['mask'] = mask\n","            results['bg_removed'] = bg_removed.copy()\n","\n","            final = bg_removed\n","\n","        elif method == 'simplev2': # Gaussian + Green mask v2\n","            denoised = self.remove_noise(resized, method='gaussian')\n","            results['denoised'] = denoised.copy()\n","\n","            bg_removed, mask = self.remove_background_green_mask_v2(denoised)\n","            results['mask'] = mask\n","            results['bg_removed'] = bg_removed.copy()\n","\n","            final = bg_removed\n","\n","        elif method == 'grabcut': # GrabCut-based\n","            denoised = self.remove_noise(resized, method='bilateral')\n","            results['denoised'] = denoised.copy()\n","\n","            bg_removed, mask = self.remove_background_grabcut(denoised)\n","            results['mask'] = mask\n","            results['bg_removed'] = bg_removed.copy()\n","\n","            final = bg_removed\n","\n","        elif method == 'hybrid': # 색상 + GrabCut\n","            denoised = self.remove_noise(resized, method='bilateral')\n","            results['denoised'] = denoised.copy()\n","\n","            bg_removed, mask = self.remove_background_hybrid(denoised)\n","            results['mask'] = mask\n","            results['bg_removed'] = bg_removed.copy()\n","\n","            final = bg_removed\n","\n","        elif method == 'advanced': # includes Watershed\n","            denoised = self.remove_noise(resized, method='bilateral')\n","            results['denoised'] = denoised.copy()\n","\n","            bg_removed, mask = self.remove_background_green_mask_v2(denoised)\n","            results['mask'] = mask\n","            results['bg_removed'] = bg_removed.copy()\n","\n","            watershed_result, markers = self.watershed_segmentation(bg_removed)\n","            results['watershed'] = watershed_result.copy()\n","\n","            final = bg_removed\n","\n","        # Final resize (model input size)\n","        final_resized = cv2.resize(final, self.target_size)\n","        results['final'] = final_resized\n","\n","        return final_resized, results\n","\n","    def visualize_results(self, results, save_path=None):\n","        n_images = len(results)\n","        cols = 3\n","        rows = (n_images + cols - 1) // cols\n","\n","        fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n","        axes = axes.flatten() if n_images > 1 else [axes]\n","\n","        for idx, (name, img) in enumerate(results.items()):\n","            if idx >= len(axes):\n","                break\n","\n","            if len(img.shape) == 2:  # Grayscale or mask\n","                axes[idx].imshow(img, cmap='gray')\n","            else:\n","                axes[idx].imshow(img)\n","            axes[idx].set_title(name.replace('_', ' ').title())\n","            axes[idx].axis('off')\n","\n","        # Remove empty subplot\n","        for idx in range(n_images, len(axes)):\n","            axes[idx].axis('off')\n","\n","        plt.tight_layout()\n","\n","        if save_path:\n","            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n","\n","        plt.show()\n"],"metadata":{"id":"B23XdFPEXcZ2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Run PlantDoc Segmentation"],"metadata":{"id":"sqdZEgLIokpw"}},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","from pathlib import Path\n","from tqdm import tqdm\n","import json\n","\n","def batch_preprocess_dataset(input_dir, output_dir, method='simple', target_size=(224, 224)):\n","    \"\"\"\n","    전체 데이터셋을 일괄 전처리\n","\n","    Args:\n","        input_dir: 원본 이미지 디렉토리\n","        output_dir: 전처리된 이미지 저장 디렉토리\n","        method: 'simple', 'grabcut', 'advanced'\n","        target_size: 최종 이미지 크기\n","    \"\"\"\n","    preprocessor = LeafPreprocessor(target_size=target_size)\n","\n","    # 출력 디렉토리 생성\n","    Path(output_dir).mkdir(parents=True, exist_ok=True)\n","\n","    image_extensions = ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']\n","    image_files = []\n","\n","    for ext in image_extensions:\n","        image_files.extend(Path(input_dir).rglob(f'*{ext}'))\n","\n","    print(f\"Found {len(image_files)} images\")\n","\n","    # 통계 수집\n","    stats = {\n","        'total': len(image_files),\n","        'success': 0,\n","        'failed': 0,\n","        'failed_files': []\n","    }\n","\n","    # 일괄 처리\n","    for img_path in tqdm(image_files, desc=\"Processing images\"):\n","        try:\n","            # 전처리 실행\n","            processed, _ = preprocessor.preprocess_pipeline(str(img_path), method=method)\n","\n","            # 상대 경로 유지하며 저장\n","            rel_path = img_path.relative_to(input_dir)\n","            output_path = Path(output_dir) / rel_path\n","            output_path.parent.mkdir(parents=True, exist_ok=True)\n","\n","            # 저장 (RGB -> BGR for OpenCV)\n","            cv2.imwrite(str(output_path), cv2.cvtColor(processed, cv2.COLOR_RGB2BGR))\n","\n","            stats['success'] += 1\n","\n","        except Exception as e:\n","            print(f\"\\nError processing {img_path}: {e}\")\n","            stats['failed'] += 1\n","            stats['failed_files'].append(str(img_path))\n","\n","    # 통계 저장\n","    with open(Path(output_dir) / 'preprocessing_stats.json', 'w') as f:\n","        json.dump(stats, f, indent=2)\n","\n","    print(f\"\\n{'='*50}\")\n","    print(f\"Preprocessing completed!\")\n","    print(f\"Success: {stats['success']}/{stats['total']}\")\n","    print(f\"Failed: {stats['failed']}/{stats['total']}\")\n","    print(f\"Results saved to: {output_dir}\")\n","    print(f\"{'='*50}\")\n","\n","    return stats"],"metadata":{"id":"q1vx-5HJoQHZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    print(\"\\n\\nBatch preprocessing\")\n","    batch_preprocess_dataset(\n","        input_dir=\"/content/drive/MyDrive/CV/25-2컴비/PlantDoc-Dataset/test\",\n","        output_dir=\"/content/drive/MyDrive/CV/25-2컴비/PlantDoc-Dataset/processed_advanced_test\",\n","        method='advanced'\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ez6hWxhSAkAn","executionInfo":{"status":"ok","timestamp":1765584182666,"user_tz":-540,"elapsed":100159,"user":{"displayName":"‎김민지(인공지능대학 인공지능학과)","userId":"04033818291171900415"}},"outputId":"eab1969f-9d58-41f4-ba7e-15eb91ba0982"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Batch preprocessing\n","Found 236 images\n"]},{"output_type":"stream","name":"stderr","text":["Processing images: 100%|██████████| 236/236 [01:39<00:00,  2.36it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","Preprocessing completed!\n","Success: 236/236\n","Failed: 0/236\n","Results saved to: /content/drive/MyDrive/CV/25-2컴비/PlantDoc-Dataset/processed_advanced_test\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["### Run PlantVillage Segmentation"],"metadata":{"id":"x-e8isvTUj3T"}},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","from pathlib import Path\n","from tqdm import tqdm\n","import json\n","\n","def batch_preprocess_dataset(input_dir, output_dir, method1='simple', method2='hybrid',target_size=(224, 224)):\n","\n","    preprocessor = LeafPreprocessor(target_size=target_size)\n","\n","    # 출력 디렉토리 생성\n","    Path(output_dir).mkdir(parents=True, exist_ok=True)\n","\n","    image_extensions = ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']\n","    image_files = []\n","\n","    for ext in image_extensions:\n","        image_files.extend(Path(input_dir).rglob(f'*{ext}'))\n","\n","    print(f\"Found {len(image_files)} images\")\n","\n","    # 통계 수집\n","    stats = {\n","        'total': len(image_files),\n","        'success': 0,\n","        'failed': 0,\n","        'failed_files': []\n","    }\n","\n","    # 일괄 처리\n","    for img_path in tqdm(image_files, desc=\"Processing images\"):\n","        try:\n","            # --------------method 결정-----------------\n","            folder_name = img_path.parent.name.lower()\n","\n","            if \"healthy\" in folder_name:\n","                applied_method = method1\n","            else:\n","                applied_method = method2\n","            # ------------------------------------------\n","\n","            processed, _ = preprocessor.preprocess_pipeline(\n","                str(img_path),\n","                method=applied_method\n","            )\n","\n","            # 상대 경로 유지하며 저장\n","            rel_path = img_path.relative_to(input_dir)\n","            output_path = Path(output_dir) / rel_path\n","            output_path.parent.mkdir(parents=True, exist_ok=True)\n","\n","            # 저장 (RGB -> BGR for OpenCV)\n","            cv2.imwrite(str(output_path), cv2.cvtColor(processed, cv2.COLOR_RGB2BGR))\n","\n","            stats['success'] += 1\n","\n","        except Exception as e:\n","            print(f\"\\nError processing {img_path}: {e}\")\n","            stats['failed'] += 1\n","            stats['failed_files'].append(str(img_path))\n","\n","    # 통계 저장\n","    with open(Path(output_dir) / 'preprocessing_stats.json', 'w') as f:\n","        json.dump(stats, f, indent=2)\n","\n","    print(f\"\\n{'='*50}\")\n","    print(f\"Preprocessing completed!\")\n","    print(f\"Success: {stats['success']}/{stats['total']}\")\n","    print(f\"Failed: {stats['failed']}/{stats['total']}\")\n","    print(f\"Results saved to: {output_dir}\")\n","    print(f\"{'='*50}\")\n","\n","    return stats"],"metadata":{"id":"A8g0ShXyU7ir"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    print(\"\\n\\nBatch preprocessing\")\n","    batch_preprocess_dataset(\n","        input_dir=\"/content/drive/MyDrive/CV/25-2컴비/PlantVillage/test\",\n","        output_dir=\"/content/drive/MyDrive/CV/25-2컴비/PlantVillage/processed_advanced_test\",\n","        method1='simple',\n","        method2='hybrid',\n","    )"],"metadata":{"id":"dvjG_fEEoTTo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e1dbf48c-0fef-4d49-b04c-7c7f86f07a2b","executionInfo":{"status":"ok","timestamp":1764085963840,"user_tz":-540,"elapsed":3068922,"user":{"displayName":"‎김민지(인공지능대학 인공지능학과)","userId":"04033818291171900415"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Batch preprocessing\n","Found 2009 images\n"]},{"output_type":"stream","name":"stderr","text":["Processing images: 100%|██████████| 2009/2009 [51:04<00:00,  1.53s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","Preprocessing completed!\n","Success: 2009/2009\n","Failed: 0/2009\n","Results saved to: /content/drive/MyDrive/CV/25-2컴비/PlantVillage/processed_advanced_test\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}